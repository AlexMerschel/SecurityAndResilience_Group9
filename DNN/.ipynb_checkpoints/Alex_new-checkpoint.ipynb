{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import  Dense, Dropout, Activation, Input, Convolution2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "# from tensorflow.keras.layers.normalization import BatchNormalization # new!\n",
    "import cv2\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function provided by the GTSRB http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset\n",
    "# function for reading the images\n",
    "# arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "# returns: list of images, list of corresponding labels\n",
    "\n",
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            images.append(plt.imread(prefix + row[0])) # the 1th column is the filename\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels\n",
    "\n",
    "# Run above function to import images and labels for training\n",
    "trainImages, trainLabels = readTrafficSigns(\"../data/train/GTSRB/Final_Training/Images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test images\n",
    "\n",
    "def readTestData(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    prefix = rootpath + '/' # subdirectory for class\n",
    "    gtFile = open(prefix + 'GT-final_test.csv') # annotations file\n",
    "    gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "    next(gtReader) # skip header\n",
    "    # loop over all images in current annotations file\n",
    "    for row in gtReader:\n",
    "        images.append(plt.imread(prefix + 'GTSRB/Final_Test/Images/' + row[0])) # the 1th column is the filename\n",
    "        labels.append(row[7]) # the 8th column is the label\n",
    "    gtFile.close()\n",
    "    return images, labels\n",
    "\n",
    "# Run above function to import images and labels for testing\n",
    "testImages, testLabels = readTestData('../data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training images\n",
    "final_images=[]\n",
    "dim = (40, 40) \n",
    "for l in range(len(trainImages)):\n",
    "    temp_img = (cv2.resize(trainImages[l], dim))\n",
    "    final_images.append(rgb2gray(temp_img))\n",
    "\n",
    "X = np.array(final_images)\n",
    "Y = np.array(trainLabels).astype(int)\n",
    "X =X.reshape([-1,40, 40,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process testing images\n",
    "final_test_images = []\n",
    "dim = (40, 40)\n",
    "for l in range(len(testImages)):\n",
    "    temp_img = (cv2.resize(testImages[l], dim))\n",
    "    final_test_images.append(rgb2gray(temp_img))\n",
    "    \n",
    "X_test = np.array(final_test_images)\n",
    "Y_test = np.array(testLabels).astype(int)\n",
    "X_test =X_test.reshape([-1,40, 40,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model for the DNN\n",
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(40,40,1)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(32))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy', 'recall', 'precision'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(X, Y,epochs=15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing data\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for future use\n",
    "model.save(\"./resources/Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model in future use\n",
    "model = tf.keras.models.load_model(\"./resources/Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model on a set of manipulated images\n",
    "# argument: Type of manipulated images to test on\n",
    "# following options for the argument:\n",
    "# - Blur\n",
    "# - Distort\n",
    "# - OnePixel\n",
    "# - Ripple\n",
    "# - Rotate\n",
    "# - saltNppr\n",
    "def testModelOnManipulatedImages(type):\n",
    "    TempImages = []\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    dim = (40,40)\n",
    "    path = '../data/GTSRB_test_manipulated/' + type\n",
    "    for file in os.listdir(path):\n",
    "        TempImages.append(plt.imread(path + '/' + file))\n",
    "        Labels.append(int(file[:2]))\n",
    "    for x in range(len(TempImages)):\n",
    "        tempImg = (cv2.resize(TempImages[x], dim))\n",
    "        Images.append(rgb2gray(tempImg))\n",
    "    Images = np.array(Images).reshape([-1,40,40,1])\n",
    "    # show one image as an example\n",
    "    plt.imshow(Images[0].reshape(40,40))\n",
    "    y_pred = model.predict(Images, verbose=1)\n",
    "    pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    print(classification_report(Labels, pred_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelOnManipulatedImages('Blur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelOnManipulatedImages('Distort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelOnManipulatedImages('OnePixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelOnManipulatedImages('Ripple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelOnManipulatedImages('Rotate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModelOnManipulatedImages('saltNppr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyImage(path):\n",
    "    image = plt.imread(path)\n",
    "    image = cv2.resize(image, dim)\n",
    "    image = rgb2gray(image)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    image = image.reshape(-1, 40, 40, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set labels for further reference\n",
    "labels = ['Speed limit (20)']\n",
    "labels.append('Speed limit (30)')\n",
    "labels.append('Speed limit (50)')\n",
    "labels.append('Speed limit (60)')\n",
    "labels.append('Speed limit (70)')\n",
    "labels.append('Speed limit (80)')\n",
    "labels.append('End of speed limit (80)')\n",
    "labels.append('Speed limit (100)')\n",
    "labels.append('Speed limit (120)')\n",
    "labels.append('No passing')\n",
    "labels.append('No passing for vehicles over 3.5 tons')\n",
    "labels.append('Right-of-way at the next intersection')\n",
    "labels.append('Priority road')\n",
    "labels.append('Yield')\n",
    "labels.append('Stop')\n",
    "labels.append('No vehicles')\n",
    "labels.append('Vehicles over 3.5 tons prohibited')\n",
    "labels.append('No entry - one way')\n",
    "labels.append('General Caution')\n",
    "labels.append('Dangerous curve to the left')\n",
    "labels.append('Dangerous curve to the right')\n",
    "labels.append('Double curve')\n",
    "labels.append('Bumpy road')\n",
    "labels.append('Slippery road')\n",
    "labels.append('Road narrows on the right')\n",
    "labels.append('Road work')\n",
    "labels.append('Traffic signals')\n",
    "labels.append('Pedestrians')\n",
    "labels.append('Children crossing')\n",
    "labels.append('Bicycles crossing')\n",
    "labels.append('Beware of ice/snow')\n",
    "labels.append('Wild animals crossing')\n",
    "labels.append('End of all speed and passing limits')\n",
    "labels.append('Turn right ahead')\n",
    "labels.append('Turn left ahead')\n",
    "labels.append('Ahead only')\n",
    "labels.append('Go straight or right')\n",
    "labels.append('Go straight or left')\n",
    "labels.append('Keep right')\n",
    "labels.append('Keep left')\n",
    "labels.append('Roundabout mandatory')\n",
    "labels.append('End of no passing')\n",
    "labels.append('End of no passing by vehicles over 3.5 tons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add set of manipulated images to the training data for a new model\n",
    "tmpNewImages = []\n",
    "tmpNewLabels = []\n",
    "\n",
    "rootpath = '../data/manipulated_train'\n",
    "for folder in os.listdir(rootpath):\n",
    "    path = rootpath + '/'  + folder\n",
    "    for file in os.listdir(path):\n",
    "        tmpNewImages.append(plt.imread(path + '/' + file))\n",
    "        tmpNewLabels.append(int(file[:2]))\n",
    "\n",
    "\n",
    "finalNewImages=[]\n",
    "dim = (40, 40) \n",
    "for l in range(len(tmpNewImages)):\n",
    "    temp_img = (cv2.resize(tmpNewImages[l], dim))\n",
    "    finalNewImages.append(rgb2gray(temp_img))\n",
    "\n",
    "    \n",
    "X_new = np.array(finalNewImages)\n",
    "Y_new = np.array(tmpNewLabels)\n",
    "X_new =X_new.reshape([-1,40, 40,1])\n",
    "Y_new =Y_new.astype(int)\n",
    "Y_new.dtype\n",
    "    \n",
    "\n",
    "newTrainImages = np.concatenate((X, X_new))\n",
    "newTrainLabels = np.concatenate((Y, Y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model, identical to the prior model\n",
    "model_new = Sequential()\n",
    "model_new.add(tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(40,40,1)))\n",
    "\n",
    "model_new.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_new.add(Dropout(0.25))\n",
    "\n",
    "model_new.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model_new.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_new.add(Dropout(0.25))\n",
    "\n",
    "model_new.add(Dense(32))\n",
    "\n",
    "model_new.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\n",
    "model_new.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_new.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_new.add(Dropout(0.25))\n",
    "\n",
    "model_new.add(Flatten())\n",
    "model_new.add(Dense(512, activation='relu'))\n",
    "model_new.add(Dropout(0.5))\n",
    "model_new.add(Dense(43, activation='softmax'))\n",
    "\n",
    "model_new.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train said model on the new training set including manipulated images\n",
    "model_new.fit(newTrainImages, newTrainLabels,epochs=15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the new model on the original test data\n",
    "model_new.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for future use\n",
    "model_new.save(\"./resources/Model_New.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_new = tf.keras.models.load_model(\"./resources/Model_New.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the new model on a set of manipulated images\n",
    "# argument: Type of manipulated images to test on\n",
    "# following options for the argument:\n",
    "# - Blur\n",
    "# - Distort\n",
    "# - OnePixel\n",
    "# - Ripple\n",
    "# - Rotate\n",
    "# - saltNppr\n",
    "def testNewModelOnManipulatedImages(type):\n",
    "    TempImages = []\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    dim = (40,40)\n",
    "    path = '../data/GTSRB_test_manipulated/' + type\n",
    "    for file in os.listdir(path):\n",
    "        TempImages.append(plt.imread(path + '/' + file))\n",
    "        Labels.append(int(file[:2]))\n",
    "    for x in range(len(TempImages)):\n",
    "        tempImg = (cv2.resize(TempImages[x], dim))\n",
    "        Images.append(rgb2gray(tempImg))\n",
    "    Images = np.array(Images).reshape([-1,40,40,1])\n",
    "    # show one image as an example\n",
    "    plt.imshow(Images[0].reshape(40,40))\n",
    "    y_pred = model_new.predict(Images, verbose=1)\n",
    "    pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    print(classification_report(Labels, pred_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewModelOnManipulatedImages('Blur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewModelOnManipulatedImages('Distort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewModelOnManipulatedImages('OnePixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewModelOnManipulatedImages('Ripple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewModelOnManipulatedImages('Rotate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNewModelOnManipulatedImages('saltNppr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
